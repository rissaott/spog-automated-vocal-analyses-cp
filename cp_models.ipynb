{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression for Canonical Proportion as a Predictor of Standardized Speech Assessments\n",
    "\n",
    "The following notebook contains code to perform multiple linear regression for canonical proportion (CP) as a predictor of the following standardized speech assessments:\n",
    "- GFTA\n",
    "- CTOPP\n",
    "- PPVT\n",
    "- NWR\n",
    "- RWR\n",
    "\n",
    "The following variables were used as covariates:\n",
    "- gender (dummy)\n",
    "- age\n",
    "- maternal education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GFTA-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unweighted, Unscaled (Baseline vs. Expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Load in data\n",
    "df = pd.read_csv('gfta_ppvt_ctopp_cp_rwr_nwr_me.csv')  # Replace with your actual file path\n",
    "\n",
    "# Check for missing values and drop rows with missing data in important columns\n",
    "df_clean = df.dropna(subset=['GFTA_Standard', 'canonical_proportion', 'age_mos', 'gender', 'Maternal_Education_Level'])\n",
    "\n",
    "# Center and scale 'age_mos' and 'Maternal_Education_Level'\n",
    "scaler = StandardScaler()\n",
    "df_clean['age_mos_scaled'] = scaler.fit_transform(df_clean[['age_mos']])\n",
    "df_clean['Maternal_Education_Level_scaled'] = scaler.fit_transform(df_clean[['Maternal_Education_Level']])\n",
    "df_clean['canonical_proportion_scaled'] = scaler.fit_transform(df_clean[['canonical_proportion']])\n",
    "\n",
    "# Manually dummy code gender as 0 = Male, 1 = Female\n",
    "df_clean['gender_dummy'] = df_clean['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Define the predictors for both the baseline and expanded models\n",
    "baseline_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled']\n",
    "expanded_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled', 'canonical_proportion_scaled']\n",
    "\n",
    "# Function to fit and return model and log-likelihood\n",
    "def fit_model(outcome_var, predictors):\n",
    "    X = df_clean[predictors]  # Predictor variables\n",
    "    X = sm.add_constant(X)  # Add an intercept (constant) to the model\n",
    "    y = df_clean[outcome_var]  # Outcome variable\n",
    "    \n",
    "    # Fit the model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit the baseline model for GFTA\n",
    "gfta_baseline_model = fit_model('GFTA_Standard', baseline_predictors)\n",
    "\n",
    "# Fit the expanded model for GFTA (adding canonical_proportion)\n",
    "gfta_expanded_model = fit_model('GFTA_Standard', expanded_predictors)\n",
    "\n",
    "# Log-likelihoods of both models\n",
    "log_likelihood_baseline = gfta_baseline_model.llf  # Log-likelihood of the baseline model\n",
    "log_likelihood_expanded = gfta_expanded_model.llf  # Log-likelihood of the expanded model\n",
    "\n",
    "# Number of parameters in each model\n",
    "k_baseline = len(gfta_baseline_model.params)  # Number of parameters in baseline model\n",
    "k_expanded = len(gfta_expanded_model.params)  # Number of parameters in expanded model\n",
    "\n",
    "# Likelihood ratio test statistic (LRT)\n",
    "lrt_statistic = 2 * (log_likelihood_expanded - log_likelihood_baseline)\n",
    "\n",
    "# Degrees of freedom (df) is the difference in the number of parameters\n",
    "df = k_expanded - k_baseline\n",
    "\n",
    "# p-value from chi-squared distribution\n",
    "p_value = chi2.sf(lrt_statistic, df)\n",
    "\n",
    "# Output the results\n",
    "print(\"Baseline Model: Demographic Factors as predictors of GFTA_Standard\")\n",
    "print(gfta_baseline_model.summary())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Expanded Model: Demographic Factors and Canonical Proportion as predictors of GFTA_Standard\")\n",
    "print(gfta_expanded_model.summary())\n",
    "\n",
    "print(\"\\nLikelihood Ratio Test Results:\")\n",
    "print(f\"Log-Likelihood of Baseline Model: {log_likelihood_baseline}\")\n",
    "print(f\"Log-Likelihood of Expanded Model: {log_likelihood_expanded}\")\n",
    "print(f\"Likelihood Ratio Statistic: {lrt_statistic}\")\n",
    "print(f\"Degrees of Freedom: {df}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference between the models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the models is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted, Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Load in data\n",
    "df = pd.read_csv('gfta_ppvt_ctopp_cp_rwr_nwr_me.csv')  # Replace with your actual file path\n",
    "\n",
    "# Check for missing values and drop rows with missing data in important columns\n",
    "df_clean = df.dropna(subset=['GFTA_Standard', 'canonical_proportion', 'age_mos', 'gender', 'Maternal_Education_Level'])\n",
    "\n",
    "# Center and scale 'age_mos' and 'Maternal_Education_Level'\n",
    "scaler = StandardScaler()\n",
    "df_clean['GFTA_Standard_scaled'] = scaler.fit_transform(df_clean[['GFTA_Standard']])\n",
    "df_clean['age_mos_scaled'] = scaler.fit_transform(df_clean[['age_mos']])\n",
    "df_clean['Maternal_Education_Level_scaled'] = scaler.fit_transform(df_clean[['Maternal_Education_Level']])\n",
    "df_clean['canonical_proportion_scaled'] = scaler.fit_transform(df_clean[['canonical_proportion']])\n",
    "\n",
    "# Manually dummy code gender as 0 = Male, 1 = Female\n",
    "df_clean['gender_dummy'] = df_clean['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Calculate a weight for each child based on their number of canonical and noncanonical clips\n",
    "# We will add these columns together and normalize it so the sum of weights is 1\n",
    "df_clean['clip_count'] = df_clean[['0', '1']].sum(axis=1)\n",
    "\n",
    "# Normalize the weight column to ensure it sums to 1 (optional step)\n",
    "df_clean['weights'] = df_clean['clip_count'] / df_clean['clip_count'].sum()\n",
    "\n",
    "# Define the predictors for both the baseline and expanded models\n",
    "baseline_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled']\n",
    "expanded_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled', 'canonical_proportion_scaled']\n",
    "\n",
    "# Function to fit and return model and log-likelihood\n",
    "def fit_model(outcome_var, predictors, weights):\n",
    "    X = df_clean[predictors]  # Predictor variables\n",
    "    X = sm.add_constant(X)  # Add an intercept (constant) to the model\n",
    "    y = df_clean[outcome_var]  # Outcome variable\n",
    "    \n",
    "    # Fit the model with weights\n",
    "    model = sm.WLS(y, X, weights=weights).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit the baseline model for GFTA\n",
    "gfta_baseline_model = fit_model('GFTA_Standard_scaled', baseline_predictors, df_clean['weights'])\n",
    "\n",
    "# Fit the expanded model for GFTA (adding canonical_proportion)\n",
    "gfta_expanded_model = fit_model('GFTA_Standard_scaled', expanded_predictors, df_clean['weights'])\n",
    "\n",
    "# Log-likelihoods of both models\n",
    "log_likelihood_baseline = gfta_baseline_model.llf  # Log-likelihood of the baseline model\n",
    "log_likelihood_expanded = gfta_expanded_model.llf  # Log-likelihood of the expanded model\n",
    "\n",
    "# Number of parameters in each model\n",
    "k_baseline = len(gfta_baseline_model.params)  # Number of parameters in baseline model\n",
    "k_expanded = len(gfta_expanded_model.params)  # Number of parameters in expanded model\n",
    "\n",
    "# Likelihood ratio test statistic (LRT)\n",
    "lrt_statistic = 2 * (log_likelihood_expanded - log_likelihood_baseline)\n",
    "\n",
    "# Degrees of freedom (df) is the difference in the number of parameters\n",
    "df = k_expanded - k_baseline\n",
    "\n",
    "# p-value from chi-squared distribution\n",
    "p_value = chi2.sf(lrt_statistic, df)\n",
    "\n",
    "# Output the results\n",
    "print(\"Baseline Model: Demographic Factors as predictors of GFTA_Standard\")\n",
    "print(gfta_baseline_model.summary())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Expanded Model: Demographic Factors and Canonical Proportion as predictors of GFTA_Standard\")\n",
    "print(gfta_expanded_model.summary())\n",
    "\n",
    "print(\"\\nLikelihood Ratio Test Results:\")\n",
    "print(f\"Log-Likelihood of Baseline Model: {log_likelihood_baseline}\")\n",
    "print(f\"Log-Likelihood of Expanded Model: {log_likelihood_expanded}\")\n",
    "print(f\"Likelihood Ratio Statistic: {lrt_statistic}\")\n",
    "print(f\"Degrees of Freedom: {df}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference between the models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the models is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPVT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unweighted, Unscaled (Baseline vs. Expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Load in data\n",
    "df = pd.read_csv('gfta_ppvt_ctopp_cp_rwr_nwr_me.csv')  # Replace with your actual file path\n",
    "\n",
    "# Check for missing values and drop rows with missing data in important columns\n",
    "df_clean = df.dropna(subset=['PPVT_Standard', 'canonical_proportion', 'age_mos', 'gender', 'Maternal_Education_Level'])\n",
    "\n",
    "# Center and scale 'age_mos' and 'Maternal_Education_Level'\n",
    "scaler = StandardScaler()\n",
    "df_clean['age_mos_scaled'] = scaler.fit_transform(df_clean[['age_mos']])\n",
    "df_clean['Maternal_Education_Level_scaled'] = scaler.fit_transform(df_clean[['Maternal_Education_Level']])\n",
    "df_clean['canonical_proportion_scaled'] = scaler.fit_transform(df_clean[['canonical_proportion']])\n",
    "\n",
    "# Manually dummy code gender as 0 = Male, 1 = Female\n",
    "df_clean['gender_dummy'] = df_clean['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Define the predictors for both the baseline and expanded models\n",
    "baseline_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled']\n",
    "expanded_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled', 'canonical_proportion_scaled']\n",
    "\n",
    "# Function to fit and return model and log-likelihood\n",
    "def fit_model(outcome_var, predictors):\n",
    "    X = df_clean[predictors]  # Predictor variables\n",
    "    X = sm.add_constant(X)  # Add an intercept (constant) to the model\n",
    "    y = df_clean[outcome_var]  # Outcome variable\n",
    "    \n",
    "    # Fit the model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit the baseline model for GFTA\n",
    "ppvt_baseline_model = fit_model('PPVT_Standard', baseline_predictors)\n",
    "\n",
    "# Fit the expanded model for GFTA (adding canonical_proportion)\n",
    "ppvt_expanded_model = fit_model('PPVT_Standard', expanded_predictors)\n",
    "\n",
    "# Log-likelihoods of both models\n",
    "log_likelihood_baseline = ppvt_baseline_model.llf  # Log-likelihood of the baseline model\n",
    "log_likelihood_expanded = ppvt_expanded_model.llf  # Log-likelihood of the expanded model\n",
    "\n",
    "# Number of parameters in each model\n",
    "k_baseline = len(ppvt_baseline_model.params)  # Number of parameters in baseline model\n",
    "k_expanded = len(ppvt_expanded_model.params)  # Number of parameters in expanded model\n",
    "\n",
    "# Likelihood ratio test statistic (LRT)\n",
    "lrt_statistic = 2 * (log_likelihood_expanded - log_likelihood_baseline)\n",
    "\n",
    "# Degrees of freedom (df) is the difference in the number of parameters\n",
    "df = k_expanded - k_baseline\n",
    "\n",
    "# p-value from chi-squared distribution\n",
    "p_value = chi2.sf(lrt_statistic, df)\n",
    "\n",
    "# Output the results\n",
    "print(\"Baseline Model: Demographic Factors as predictors of PPVT_Standard\")\n",
    "print(ppvt_baseline_model.summary())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Expanded Model: Demographic Factors and Canonical Proportion as predictors of PPVT_Standard\")\n",
    "print(ppvt_expanded_model.summary())\n",
    "\n",
    "print(\"\\nLikelihood Ratio Test Results:\")\n",
    "print(f\"Log-Likelihood of Baseline Model: {log_likelihood_baseline}\")\n",
    "print(f\"Log-Likelihood of Expanded Model: {log_likelihood_expanded}\")\n",
    "print(f\"Likelihood Ratio Statistic: {lrt_statistic}\")\n",
    "print(f\"Degrees of Freedom: {df}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference between the models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the models is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted, Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Load in data\n",
    "df = pd.read_csv('gfta_ppvt_ctopp_cp_rwr_nwr_me.csv')  # Replace with your actual file path\n",
    "\n",
    "# Check for missing values and drop rows with missing data in important columns\n",
    "df_clean = df.dropna(subset=['PPVT_Standard', 'canonical_proportion', 'age_mos', 'gender', 'Maternal_Education_Level'])\n",
    "\n",
    "# Center and scale 'age_mos' and 'Maternal_Education_Level'\n",
    "scaler = StandardScaler()\n",
    "df_clean['PPVT_Standard_scaled'] = scaler.fit_transform(df_clean[['PPVT_Standard']])\n",
    "df_clean['age_mos_scaled'] = scaler.fit_transform(df_clean[['age_mos']])\n",
    "df_clean['Maternal_Education_Level_scaled'] = scaler.fit_transform(df_clean[['Maternal_Education_Level']])\n",
    "df_clean['canonical_proportion_scaled'] = scaler.fit_transform(df_clean[['canonical_proportion']])\n",
    "\n",
    "# Manually dummy code gender as 0 = Male, 1 = Female\n",
    "df_clean['gender_dummy'] = df_clean['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Calculate a weight for each child based on their number of canonical and noncanonical clips\n",
    "# Sum the values from columns '0' and '1' to get the clip count per child\n",
    "df_clean['clip_count'] = df_clean[['0', '1']].sum(axis=1)\n",
    "\n",
    "# Normalize the weight column to ensure it sums to 1 (optional step)\n",
    "df_clean['weights'] = df_clean['clip_count'] / df_clean['clip_count'].sum()\n",
    "\n",
    "# Define the predictors for both the baseline and expanded models\n",
    "baseline_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled']\n",
    "expanded_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled', 'canonical_proportion_scaled']\n",
    "\n",
    "# Function to fit and return model and log-likelihood\n",
    "def fit_model(outcome_var, predictors, weights):\n",
    "    X = df_clean[predictors]  # Predictor variables\n",
    "    X = sm.add_constant(X)  # Add an intercept (constant) to the model\n",
    "    y = df_clean[outcome_var]  # Outcome variable\n",
    "    \n",
    "    # Fit the model with weights\n",
    "    model = sm.WLS(y, X, weights=weights).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit the baseline model for PPVT\n",
    "ppvt_baseline_model = fit_model('PPVT_Standard_scaled', baseline_predictors, df_clean['weights'])\n",
    "\n",
    "# Fit the expanded model for PPVT (adding canonical_proportion)\n",
    "ppvt_expanded_model = fit_model('PPVT_Standard_scaled', expanded_predictors, df_clean['weights'])\n",
    "\n",
    "# Log-likelihoods of both models\n",
    "log_likelihood_baseline = ppvt_baseline_model.llf  # Log-likelihood of the baseline model\n",
    "log_likelihood_expanded = ppvt_expanded_model.llf  # Log-likelihood of the expanded model\n",
    "\n",
    "# Number of parameters in each model\n",
    "k_baseline = len(ppvt_baseline_model.params)  # Number of parameters in baseline model\n",
    "k_expanded = len(ppvt_expanded_model.params)  # Number of parameters in expanded model\n",
    "\n",
    "# Likelihood ratio test statistic (LRT)\n",
    "lrt_statistic = 2 * (log_likelihood_expanded - log_likelihood_baseline)\n",
    "\n",
    "# Degrees of freedom (df) is the difference in the number of parameters\n",
    "df = k_expanded - k_baseline\n",
    "\n",
    "# p-value from chi-squared distribution\n",
    "p_value = chi2.sf(lrt_statistic, df)\n",
    "\n",
    "# Output the results\n",
    "print(\"Baseline Model: Demographic Factors as predictors of PPVT_Standard\")\n",
    "print(ppvt_baseline_model.summary())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Expanded Model: Demographic Factors and Canonical Proportion as predictors of PPVT_Standard\")\n",
    "print(ppvt_expanded_model.summary())\n",
    "\n",
    "print(\"\\nLikelihood Ratio Test Results:\")\n",
    "print(f\"Log-Likelihood of Baseline Model: {log_likelihood_baseline}\")\n",
    "print(f\"Log-Likelihood of Expanded Model: {log_likelihood_expanded}\")\n",
    "print(f\"Likelihood Ratio Statistic: {lrt_statistic}\")\n",
    "print(f\"Degrees of Freedom: {df}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference between the models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the models is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTOPP-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unweighted, Unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Load in data\n",
    "df = pd.read_csv('gfta_ppvt_ctopp_cp_rwr_nwr_me.csv')  # Replace with your actual file path\n",
    "\n",
    "# Check for missing values and drop rows with missing data in important columns\n",
    "df_clean = df.dropna(subset=['CTOPP_Elision_Scaled', 'canonical_proportion', 'age_mos', 'gender', 'Maternal_Education_Level'])\n",
    "\n",
    "# Center and scale 'age_mos' and 'Maternal_Education_Level'\n",
    "scaler = StandardScaler()\n",
    "df_clean['age_mos_scaled'] = scaler.fit_transform(df_clean[['age_mos']])\n",
    "df_clean['Maternal_Education_Level_scaled'] = scaler.fit_transform(df_clean[['Maternal_Education_Level']])\n",
    "df_clean['canonical_proportion_scaled'] = scaler.fit_transform(df_clean[['canonical_proportion']])\n",
    "\n",
    "# Manually dummy code gender as 0 = Male, 1 = Female\n",
    "df_clean['gender_dummy'] = df_clean['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Define the predictors for both the baseline and expanded models\n",
    "baseline_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled']\n",
    "expanded_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled', 'canonical_proportion_scaled']\n",
    "\n",
    "# Function to fit and return model and log-likelihood\n",
    "def fit_model(outcome_var, predictors):\n",
    "    X = df_clean[predictors]  # Predictor variables\n",
    "    X = sm.add_constant(X)  # Add an intercept (constant) to the model\n",
    "    y = df_clean[outcome_var]  # Outcome variable\n",
    "    \n",
    "    # Fit the model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit the baseline model for GFTA\n",
    "ctopp_baseline_model = fit_model('CTOPP_Elision_Scaled', baseline_predictors)\n",
    "\n",
    "# Fit the expanded model for GFTA (adding canonical_proportion)\n",
    "ctopp_expanded_model = fit_model('CTOPP_Elision_Scaled', expanded_predictors)\n",
    "\n",
    "# Log-likelihoods of both models\n",
    "log_likelihood_baseline = ctopp_baseline_model.llf  # Log-likelihood of the baseline model\n",
    "log_likelihood_expanded = ctopp_expanded_model.llf  # Log-likelihood of the expanded model\n",
    "\n",
    "# Number of parameters in each model\n",
    "k_baseline = len(ctopp_baseline_model.params)  # Number of parameters in baseline model\n",
    "k_expanded = len(ctopp_expanded_model.params)  # Number of parameters in expanded model\n",
    "\n",
    "# Likelihood ratio test statistic (LRT)\n",
    "lrt_statistic = 2 * (log_likelihood_expanded - log_likelihood_baseline)\n",
    "\n",
    "# Degrees of freedom (df) is the difference in the number of parameters\n",
    "df = k_expanded - k_baseline\n",
    "\n",
    "# p-value from chi-squared distribution\n",
    "p_value = chi2.sf(lrt_statistic, df)\n",
    "\n",
    "# Output the results\n",
    "print(\"Baseline Model: Demographic Factors as predictors of CTOPP_Elision_Scaled\")\n",
    "print(ctopp_baseline_model.summary())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Expanded Model: Demographic Factors and Canonical Proportion as predictors of CTOPP_Elision_Scaled\")\n",
    "print(ctopp_expanded_model.summary())\n",
    "\n",
    "print(\"\\nLikelihood Ratio Test Results:\")\n",
    "print(f\"Log-Likelihood of Baseline Model: {log_likelihood_baseline}\")\n",
    "print(f\"Log-Likelihood of Expanded Model: {log_likelihood_expanded}\")\n",
    "print(f\"Likelihood Ratio Statistic: {lrt_statistic}\")\n",
    "print(f\"Degrees of Freedom: {df}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference between the models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the models is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted, Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Load in data\n",
    "df = pd.read_csv('gfta_ppvt_ctopp_cp_rwr_nwr_me.csv')  # Replace with your actual file path\n",
    "\n",
    "# Check for missing values and drop rows with missing data in important columns\n",
    "df_clean = df.dropna(subset=['CTOPP_Elision_Scaled', 'canonical_proportion', 'age_mos', 'gender', 'Maternal_Education_Level'])\n",
    "\n",
    "# Center and scale 'age_mos' and 'Maternal_Education_Level'\n",
    "scaler = StandardScaler()\n",
    "df_clean['CTOPP_Standard_scaled'] = scaler.fit_transform(df_clean[['CTOPP_Elision_Scaled']])\n",
    "df_clean['age_mos_scaled'] = scaler.fit_transform(df_clean[['age_mos']])\n",
    "df_clean['Maternal_Education_Level_scaled'] = scaler.fit_transform(df_clean[['Maternal_Education_Level']])\n",
    "df_clean['canonical_proportion_scaled'] = scaler.fit_transform(df_clean[['canonical_proportion']])\n",
    "\n",
    "# Manually dummy code gender as 0 = Male, 1 = Female\n",
    "df_clean['gender_dummy'] = df_clean['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Calculate a weight for each child based on their number of canonical and noncanonical clips\n",
    "# Sum the values from columns '0' and '1' to get the clip count per child\n",
    "df_clean['clip_count'] = df_clean[['0', '1']].sum(axis=1)\n",
    "\n",
    "# Normalize the weight column to ensure it sums to 1 (optional step)\n",
    "df_clean['weights'] = df_clean['clip_count'] / df_clean['clip_count'].sum()\n",
    "\n",
    "# Define the predictors for both the baseline and expanded models\n",
    "baseline_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled']\n",
    "expanded_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled', 'canonical_proportion_scaled']\n",
    "\n",
    "# Function to fit and return model and log-likelihood with weighted regression (WLS)\n",
    "def fit_model(outcome_var, predictors, weights):\n",
    "    X = df_clean[predictors]  # Predictor variables\n",
    "    X = sm.add_constant(X)  # Add an intercept (constant) to the model\n",
    "    y = df_clean[outcome_var]  # Outcome variable\n",
    "    \n",
    "    # Fit the model with weights using WLS (Weighted Least Squares)\n",
    "    model = sm.WLS(y, X, weights=weights).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit the baseline model for CTOPP\n",
    "ctopp_baseline_model = fit_model('CTOPP_Standard_scaled', baseline_predictors, df_clean['weights'])\n",
    "\n",
    "# Fit the expanded model for CTOPP (adding canonical_proportion)\n",
    "ctopp_expanded_model = fit_model('CTOPP_Standard_scaled', expanded_predictors, df_clean['weights'])\n",
    "\n",
    "# Log-likelihoods of both models\n",
    "log_likelihood_baseline = ctopp_baseline_model.llf  # Log-likelihood of the baseline model\n",
    "log_likelihood_expanded = ctopp_expanded_model.llf  # Log-likelihood of the expanded model\n",
    "\n",
    "# Number of parameters in each model\n",
    "k_baseline = len(ctopp_baseline_model.params)  # Number of parameters in baseline model\n",
    "k_expanded = len(ctopp_expanded_model.params)  # Number of parameters in expanded model\n",
    "\n",
    "# Likelihood ratio test statistic (LRT)\n",
    "lrt_statistic = 2 * (log_likelihood_expanded - log_likelihood_baseline)\n",
    "\n",
    "# Degrees of freedom (df) is the difference in the number of parameters\n",
    "df = k_expanded - k_baseline\n",
    "\n",
    "# p-value from chi-squared distribution\n",
    "p_value = chi2.sf(lrt_statistic, df)\n",
    "\n",
    "# Output the results\n",
    "print(\"Baseline Model: Demographic Factors as predictors of CTOPP_Elision_Scaled\")\n",
    "print(ctopp_baseline_model.summary())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Expanded Model: Demographic Factors and Canonical Proportion as predictors of CTOPP_Elision_Scaled\")\n",
    "print(ctopp_expanded_model.summary())\n",
    "\n",
    "print(\"\\nLikelihood Ratio Test Results:\")\n",
    "print(f\"Log-Likelihood of Baseline Model: {log_likelihood_baseline}\")\n",
    "print(f\"Log-Likelihood of Expanded Model: {log_likelihood_expanded}\")\n",
    "print(f\"Likelihood Ratio Statistic: {lrt_statistic}\")\n",
    "print(f\"Degrees of Freedom: {df}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference between the models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the models is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RWR Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unweighted, Unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Load in data\n",
    "df = pd.read_csv('gfta_ppvt_ctopp_cp_rwr_nwr_me.csv')  # Replace with your actual file path\n",
    "\n",
    "# Check for missing values and drop rows with missing data in important columns\n",
    "df_clean = df.dropna(subset=['avg_rwr_accuracy', 'canonical_proportion', 'age_mos', 'gender', 'Maternal_Education_Level'])\n",
    "\n",
    "# Center and scale 'age_mos' and 'Maternal_Education_Level'\n",
    "scaler = StandardScaler()\n",
    "df_clean['age_mos_scaled'] = scaler.fit_transform(df_clean[['age_mos']])\n",
    "df_clean['Maternal_Education_Level_scaled'] = scaler.fit_transform(df_clean[['Maternal_Education_Level']])\n",
    "df_clean['canonical_proportion_scaled'] = scaler.fit_transform(df_clean[['canonical_proportion']])\n",
    "\n",
    "# Manually dummy code gender as 0 = Male, 1 = Female\n",
    "df_clean['gender_dummy'] = df_clean['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Define the predictors for both the baseline and expanded models\n",
    "baseline_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled']\n",
    "expanded_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled', 'canonical_proportion_scaled']\n",
    "\n",
    "# Function to fit and return model and log-likelihood\n",
    "def fit_model(outcome_var, predictors):\n",
    "    X = df_clean[predictors]  # Predictor variables\n",
    "    X = sm.add_constant(X)  # Add an intercept (constant) to the model\n",
    "    y = df_clean[outcome_var]  # Outcome variable\n",
    "    \n",
    "    # Fit the model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit the baseline model for GFTA\n",
    "rwr_baseline_model = fit_model('avg_rwr_accuracy', baseline_predictors)\n",
    "\n",
    "# Fit the expanded model for GFTA (adding canonical_proportion)\n",
    "rwr_expanded_model = fit_model('avg_rwr_accuracy', expanded_predictors)\n",
    "\n",
    "# Log-likelihoods of both models\n",
    "log_likelihood_baseline = rwr_baseline_model.llf  # Log-likelihood of the baseline model\n",
    "log_likelihood_expanded = rwr_expanded_model.llf  # Log-likelihood of the expanded model\n",
    "\n",
    "# Number of parameters in each model\n",
    "k_baseline = len(rwr_baseline_model.params)  # Number of parameters in baseline model\n",
    "k_expanded = len(rwr_expanded_model.params)  # Number of parameters in expanded model\n",
    "\n",
    "# Likelihood ratio test statistic (LRT)\n",
    "lrt_statistic = 2 * (log_likelihood_expanded - log_likelihood_baseline)\n",
    "\n",
    "# Degrees of freedom (df) is the difference in the number of parameters\n",
    "df = k_expanded - k_baseline\n",
    "\n",
    "# p-value from chi-squared distribution\n",
    "p_value = chi2.sf(lrt_statistic, df)\n",
    "\n",
    "# Output the results\n",
    "print(\"Baseline Model: Demographic Factors as predictors of avg_rwr_accuracy\")\n",
    "print(rwr_baseline_model.summary())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Expanded Model: Demographic Factors and Canonical Proportion as predictors of avg_rwr_accuracy\")\n",
    "print(rwr_expanded_model.summary())\n",
    "\n",
    "print(\"\\nLikelihood Ratio Test Results:\")\n",
    "print(f\"Log-Likelihood of Baseline Model: {log_likelihood_baseline}\")\n",
    "print(f\"Log-Likelihood of Expanded Model: {log_likelihood_expanded}\")\n",
    "print(f\"Likelihood Ratio Statistic: {lrt_statistic}\")\n",
    "print(f\"Degrees of Freedom: {df}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference between the models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the models is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted, Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Load in data\n",
    "df = pd.read_csv('gfta_ppvt_ctopp_cp_rwr_nwr_me.csv')  # Replace with your actual file path\n",
    "\n",
    "# Check for missing values and drop rows with missing data in important columns\n",
    "df_clean = df.dropna(subset=['avg_rwr_accuracy', 'canonical_proportion', 'age_mos', 'gender', 'Maternal_Education_Level'])\n",
    "\n",
    "# Center and scale 'age_mos' and 'Maternal_Education_Level'\n",
    "scaler = StandardScaler()\n",
    "df_clean['RWR_Standard_scaled'] = scaler.fit_transform(df_clean[['avg_rwr_accuracy']])\n",
    "df_clean['age_mos_scaled'] = scaler.fit_transform(df_clean[['age_mos']])\n",
    "df_clean['Maternal_Education_Level_scaled'] = scaler.fit_transform(df_clean[['Maternal_Education_Level']])\n",
    "df_clean['canonical_proportion_scaled'] = scaler.fit_transform(df_clean[['canonical_proportion']])\n",
    "\n",
    "# Manually dummy code gender as 0 = Male, 1 = Female\n",
    "df_clean['gender_dummy'] = df_clean['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Calculate a weight for each child based on their number of canonical and noncanonical clips\n",
    "# Sum the values from columns '0' and '1' to get the clip count per child\n",
    "df_clean['clip_count'] = df_clean[['0', '1']].sum(axis=1)\n",
    "\n",
    "# Normalize the weight column to ensure it sums to 1 (optional step)\n",
    "df_clean['weights'] = df_clean['clip_count'] / df_clean['clip_count'].sum()\n",
    "\n",
    "# Define the predictors for both the baseline and expanded models\n",
    "baseline_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled']\n",
    "expanded_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled', 'canonical_proportion_scaled']\n",
    "\n",
    "# Function to fit and return model and log-likelihood with weighted regression (WLS)\n",
    "def fit_model(outcome_var, predictors, weights):\n",
    "    X = df_clean[predictors]  # Predictor variables\n",
    "    X = sm.add_constant(X)  # Add an intercept (constant) to the model\n",
    "    y = df_clean[outcome_var]  # Outcome variable\n",
    "    \n",
    "    # Fit the model with weights using WLS (Weighted Least Squares)\n",
    "    model = sm.WLS(y, X, weights=weights).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit the baseline model for RWR\n",
    "rwr_baseline_model = fit_model('RWR_Standard_scaled', baseline_predictors, df_clean['weights'])\n",
    "\n",
    "# Fit the expanded model for RWR (adding canonical_proportion)\n",
    "rwr_expanded_model = fit_model('RWR_Standard_scaled', expanded_predictors, df_clean['weights'])\n",
    "\n",
    "# Log-likelihoods of both models\n",
    "log_likelihood_baseline = rwr_baseline_model.llf  # Log-likelihood of the baseline model\n",
    "log_likelihood_expanded = rwr_expanded_model.llf  # Log-likelihood of the expanded model\n",
    "\n",
    "# Number of parameters in each model\n",
    "k_baseline = len(rwr_baseline_model.params)  # Number of parameters in baseline model\n",
    "k_expanded = len(rwr_expanded_model.params)  # Number of parameters in expanded model\n",
    "\n",
    "# Likelihood ratio test statistic (LRT)\n",
    "lrt_statistic = 2 * (log_likelihood_expanded - log_likelihood_baseline)\n",
    "\n",
    "# Degrees of freedom (df) is the difference in the number of parameters\n",
    "df = k_expanded - k_baseline\n",
    "\n",
    "# p-value from chi-squared distribution\n",
    "p_value = chi2.sf(lrt_statistic, df)\n",
    "\n",
    "# Output the results\n",
    "print(\"Baseline Model: Demographic Factors as predictors of avg_rwr_accuracy\")\n",
    "print(rwr_baseline_model.summary())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Expanded Model: Demographic Factors and Canonical Proportion as predictors of avg_rwr_accuracy\")\n",
    "print(rwr_expanded_model.summary())\n",
    "\n",
    "print(\"\\nLikelihood Ratio Test Results:\")\n",
    "print(f\"Log-Likelihood of Baseline Model: {log_likelihood_baseline}\")\n",
    "print(f\"Log-Likelihood of Expanded Model: {log_likelihood_expanded}\")\n",
    "print(f\"Likelihood Ratio Statistic: {lrt_statistic}\")\n",
    "print(f\"Degrees of Freedom: {df}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference between the models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the models is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NWR Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unweighted, Unscaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Load in data\n",
    "df = pd.read_csv('gfta_ppvt_ctopp_cp_rwr_nwr_me.csv')  # Replace with your actual file path\n",
    "\n",
    "# Check for missing values and drop rows with missing data in important columns\n",
    "df_clean = df.dropna(subset=['avg_nwr_accuracy', 'canonical_proportion', 'age_mos', 'gender', 'Maternal_Education_Level'])\n",
    "\n",
    "# Center and scale 'age_mos' and 'Maternal_Education_Level'\n",
    "scaler = StandardScaler()\n",
    "df_clean['age_mos_scaled'] = scaler.fit_transform(df_clean[['age_mos']])\n",
    "df_clean['Maternal_Education_Level_scaled'] = scaler.fit_transform(df_clean[['Maternal_Education_Level']])\n",
    "df_clean['canonical_proportion_scaled'] = scaler.fit_transform(df_clean[['canonical_proportion']])\n",
    "\n",
    "# Manually dummy code gender as 0 = Male, 1 = Female\n",
    "df_clean['gender_dummy'] = df_clean['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Define the predictors for both the baseline and expanded models\n",
    "baseline_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled']\n",
    "expanded_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled', 'canonical_proportion_scaled']\n",
    "\n",
    "# Function to fit and return model and log-likelihood\n",
    "def fit_model(outcome_var, predictors):\n",
    "    X = df_clean[predictors]  # Predictor variables\n",
    "    X = sm.add_constant(X)  # Add an intercept (constant) to the model\n",
    "    y = df_clean[outcome_var]  # Outcome variable\n",
    "    \n",
    "    # Fit the model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit the baseline model for GFTA\n",
    "nwr_baseline_model = fit_model('avg_nwr_accuracy', baseline_predictors)\n",
    "\n",
    "# Fit the expanded model for GFTA (adding canonical_proportion)\n",
    "nwr_expanded_model = fit_model('avg_nwr_accuracy', expanded_predictors)\n",
    "\n",
    "# Log-likelihoods of both models\n",
    "log_likelihood_baseline = nwr_baseline_model.llf  # Log-likelihood of the baseline model\n",
    "log_likelihood_expanded = nwr_expanded_model.llf  # Log-likelihood of the expanded model\n",
    "\n",
    "# Number of parameters in each model\n",
    "k_baseline = len(nwr_baseline_model.params)  # Number of parameters in baseline model\n",
    "k_expanded = len(nwr_expanded_model.params)  # Number of parameters in expanded model\n",
    "\n",
    "# Likelihood ratio test statistic (LRT)\n",
    "lrt_statistic = 2 * (log_likelihood_expanded - log_likelihood_baseline)\n",
    "\n",
    "# Degrees of freedom (df) is the difference in the number of parameters\n",
    "df = k_expanded - k_baseline\n",
    "\n",
    "# p-value from chi-squared distribution\n",
    "p_value = chi2.sf(lrt_statistic, df)\n",
    "\n",
    "# Output the results\n",
    "print(\"Baseline Model: Demographic Factors as predictors of avg_nwr_accuracy\")\n",
    "print(nwr_baseline_model.summary())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Expanded Model: Demographic Factors and Canonical Proportion as predictors of avg_nwr_accuracy\")\n",
    "print(nwr_expanded_model.summary())\n",
    "\n",
    "print(\"\\nLikelihood Ratio Test Results:\")\n",
    "print(f\"Log-Likelihood of Baseline Model: {log_likelihood_baseline}\")\n",
    "print(f\"Log-Likelihood of Expanded Model: {log_likelihood_expanded}\")\n",
    "print(f\"Likelihood Ratio Statistic: {lrt_statistic}\")\n",
    "print(f\"Degrees of Freedom: {df}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference between the models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the models is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted, Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Load in data\n",
    "df = pd.read_csv('gfta_ppvt_ctopp_cp_rwr_nwr_me.csv')  # Replace with your actual file path\n",
    "\n",
    "# Check for missing values and drop rows with missing data in important columns\n",
    "df_clean = df.dropna(subset=['avg_nwr_accuracy', 'canonical_proportion', 'age_mos', 'gender', 'Maternal_Education_Level'])\n",
    "\n",
    "# Center and scale 'age_mos' and 'Maternal_Education_Level'\n",
    "scaler = StandardScaler()\n",
    "df_clean['NWR_Standard_scaled'] = scaler.fit_transform(df_clean[['avg_nwr_accuracy']])\n",
    "df_clean['age_mos_scaled'] = scaler.fit_transform(df_clean[['age_mos']])\n",
    "df_clean['Maternal_Education_Level_scaled'] = scaler.fit_transform(df_clean[['Maternal_Education_Level']])\n",
    "df_clean['canonical_proportion_scaled'] = scaler.fit_transform(df_clean[['canonical_proportion']])\n",
    "\n",
    "# Manually dummy code gender as 0 = Male, 1 = Female\n",
    "df_clean['gender_dummy'] = df_clean['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Calculate a weight for each child based on their number of canonical and noncanonical clips\n",
    "# Sum the values from columns '0' and '1' to get the clip count per child\n",
    "df_clean['clip_count'] = df_clean[['0', '1']].sum(axis=1)\n",
    "\n",
    "# Normalize the weight column to ensure it sums to 1 (optional step)\n",
    "df_clean['weights'] = df_clean['clip_count'] / df_clean['clip_count'].sum()\n",
    "\n",
    "# Define the predictors for both the baseline and expanded models\n",
    "baseline_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled']\n",
    "expanded_predictors = ['age_mos_scaled', 'gender_dummy', 'Maternal_Education_Level_scaled', 'canonical_proportion_scaled']\n",
    "\n",
    "# Function to fit and return model and log-likelihood with weighted regression (WLS)\n",
    "def fit_model(outcome_var, predictors, weights):\n",
    "    X = df_clean[predictors]  # Predictor variables\n",
    "    X = sm.add_constant(X)  # Add an intercept (constant) to the model\n",
    "    y = df_clean[outcome_var]  # Outcome variable\n",
    "    \n",
    "    # Fit the model with weights using WLS (Weighted Least Squares)\n",
    "    model = sm.WLS(y, X, weights=weights).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit the baseline model for NWR\n",
    "nwr_baseline_model = fit_model('NWR_Standard_scaled', baseline_predictors, df_clean['weights'])\n",
    "\n",
    "# Fit the expanded model for NWR (adding canonical_proportion)\n",
    "nwr_expanded_model = fit_model('NWR_Standard_scaled', expanded_predictors, df_clean['weights'])\n",
    "\n",
    "# Log-likelihoods of both models\n",
    "log_likelihood_baseline = nwr_baseline_model.llf  # Log-likelihood of the baseline model\n",
    "log_likelihood_expanded = nwr_expanded_model.llf  # Log-likelihood of the expanded model\n",
    "\n",
    "# Number of parameters in each model\n",
    "k_baseline = len(nwr_baseline_model.params)  # Number of parameters in baseline model\n",
    "k_expanded = len(nwr_expanded_model.params)  # Number of parameters in expanded model\n",
    "\n",
    "# Likelihood ratio test statistic (LRT)\n",
    "lrt_statistic = 2 * (log_likelihood_expanded - log_likelihood_baseline)\n",
    "\n",
    "# Degrees of freedom (df) is the difference in the number of parameters\n",
    "df = k_expanded - k_baseline\n",
    "\n",
    "# p-value from chi-squared distribution\n",
    "p_value = chi2.sf(lrt_statistic, df)\n",
    "\n",
    "# Output the results\n",
    "print(\"Baseline Model: Demographic Factors as predictors of avg_nwr_accuracy\")\n",
    "print(nwr_baseline_model.summary())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Expanded Model: Demographic Factors and Canonical Proportion as predictors of avg_nwr_accuracy\")\n",
    "print(nwr_expanded_model.summary())\n",
    "\n",
    "print(\"\\nLikelihood Ratio Test Results:\")\n",
    "print(f\"Log-Likelihood of Baseline Model: {log_likelihood_baseline}\")\n",
    "print(f\"Log-Likelihood of Expanded Model: {log_likelihood_expanded}\")\n",
    "print(f\"Likelihood Ratio Statistic: {lrt_statistic}\")\n",
    "print(f\"Degrees of Freedom: {df}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference between the models is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the models is not statistically significant.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
